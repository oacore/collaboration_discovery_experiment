{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/site-packages\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/site-packages (from nltk)\r\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-63a6f5d8f536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip3 install nltk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "# !pip3 install nltk\n",
    "# import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = FreqDist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for word, tag in treebank.tagged_words():\n",
    "#     fd.inc(tag)\n",
    "    fd[tag] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'PRP$', 766),\n",
       " (u'VBG', 1460),\n",
       " (u'VBD', 3043),\n",
       " (u'``', 712),\n",
       " (u'VBN', 2134),\n",
       " (u'POS', 824),\n",
       " (u\"''\", 694),\n",
       " (u'VBP', 1321),\n",
       " (u'WDT', 445),\n",
       " (u'JJ', 5834),\n",
       " (u'WP', 241),\n",
       " (u'VBZ', 2125),\n",
       " (u'DT', 8165),\n",
       " (u'#', 16),\n",
       " (u'RP', 216),\n",
       " (u'$', 724),\n",
       " (u'NN', 13166),\n",
       " (u'FW', 4),\n",
       " (u',', 4886),\n",
       " (u'.', 3874),\n",
       " (u'TO', 2179),\n",
       " (u'PRP', 1716),\n",
       " (u'RB', 2822),\n",
       " (u'-LRB-', 120),\n",
       " (u':', 563),\n",
       " (u'NNS', 6047),\n",
       " (u'NNP', 9410),\n",
       " (u'VB', 2554),\n",
       " (u'WRB', 178),\n",
       " (u'CC', 2265),\n",
       " (u'LS', 13),\n",
       " (u'PDT', 27),\n",
       " (u'RBS', 35),\n",
       " (u'RBR', 136),\n",
       " (u'CD', 3546),\n",
       " (u'-NONE-', 6592),\n",
       " (u'EX', 88),\n",
       " (u'IN', 9857),\n",
       " (u'WP$', 14),\n",
       " (u'MD', 927),\n",
       " (u'NNPS', 244),\n",
       " (u'-RRB-', 126),\n",
       " (u'JJS', 182),\n",
       " (u'JJR', 381),\n",
       " (u'SYM', 1),\n",
       " (u'UH', 3)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to see what these tags mean: http://www.comp.leeds.ac.uk/amalgam/tagsets/upenn.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20hIsS1F5j4D2C2iXrg4Wxf7VTp4Xt1j'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"api_key.secret\",\"r\") \n",
    "core_api_key=file.read()\n",
    "core_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urllib2 import urlopen\n",
    "from urllib import urlencode\n",
    "from urllib import quote_plus\n",
    "# import urllib.parse\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "class CoreApiRequestor:\n",
    "\n",
    "    def __init__(self, endpoint, api_key):\n",
    "        self.endpoint = endpoint\n",
    "        self.api_key = api_key\n",
    "        #defaults\n",
    "        self.pagesize = 100\n",
    "        self.page = 1\n",
    "\n",
    "    def parse_response(self, decoded):\n",
    "        res = []\n",
    "        for item in decoded['data']:\n",
    "            doi = None\n",
    "            if 'identifiers' in item:\n",
    "                for identifier in item['identifiers']:\n",
    "                    if identifier and identifier.startswith('doi:'):\n",
    "                        doi = identifier\n",
    "                        break\n",
    "            res.append([item['title'], doi])\n",
    "        return res\n",
    "\n",
    "    def request_url(self, url):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            html = response.read()\n",
    "        return html\n",
    "\n",
    "    def get_method_query_request_url(self,method,query,fullText,page):\n",
    "        if (fullText):\n",
    "            fullText = 'true'\n",
    "        else:\n",
    "            fullText = 'false'\n",
    "        params = {\n",
    "            'apiKey':self.api_key,\n",
    "            'page':page,\n",
    "            'pageSize':self.pagesize,\n",
    "            'fulltext':fullText\n",
    "        }\n",
    "        return self.endpoint + method + '/' + quote_plus(query) + '?' + urlencode(params)\n",
    "\n",
    "    def get_up_to_20_pages_of_query(self,method,query,fulltext):\n",
    "        url = self.get_method_query_request_url(method,query,fulltext,1)\n",
    "        all_articles=[]\n",
    "        resp = self.request_url(url)\n",
    "        result = json.loads(resp.decode('utf-8'))\n",
    "        all_articles.append(result)\n",
    "        if (result['totalHits']>100):\n",
    "            numOfPages = int(result['totalHits']/self.pagesize)  #rounds down\n",
    "            if (numOfPages>20):\n",
    "                numOfPages=20\n",
    "            for i in range(2,numOfPages):\n",
    "                url = self.get_method_query_request_url(method,query,False,i)\n",
    "                print(url)\n",
    "                resp =self.request_url(url)\n",
    "                all_articles.append(json.loads(resp.decode('utf-8')))\n",
    "        return all_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Example invokation\n",
    "'''\n",
    "# init \n",
    "endpoint = 'https://core.ac.uk/api-v2'\n",
    "\n",
    "'''\n",
    "********************************************\n",
    "Add your own api key below\n",
    "'''\n",
    "api_key = 'nTo627BU8jPNth4EbsrDue9IXWzAfZiY'\n",
    "'''\n",
    "********************************************\n",
    "'''\n",
    "method = '/articles/search'\n",
    "topic = 'repositories.id:1'\n",
    "\n",
    "api = CoreApiRequestor(endpoint,api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = api.get_method_query_request_url(method,topic,True,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://core.ac.uk/api-v2/articles/search/repositories.id%3A1?fulltext=true&apiKey=nTo627BU8jPNth4EbsrDue9IXWzAfZiY&page=1&pageSize=100'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: urllib in /Users/lucasanastasiou/anaconda/lib/python2.7/site-packages\r\n"
     ]
    }
   ],
   "source": [
    "!pip install urllib --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sys.version_info(major=2, minor=7, micro=12, releaselevel='final', serial=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version\n",
    "sys.version_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = open(\"article_19787393.txt\",\"r\") \n",
    "articleFile=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "articleFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info http://www.nltk.org/nltk_data/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = nltk.sent_tokenize(articleFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Composition was not strongly associated with modulus; water and collagen contents together \\npredicted about 25 % of the variance in modulus.'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[16]\n",
    "# pp.pprint(tokenized_sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp= pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_tagged_0 = nltk.pos_tag(tokenized_sentences[0])\n",
    "pp.pprint(sentences[0])\n",
    "pp.pprint(tokenized_sentences[0])\n",
    "pp.pprint(pos_tagged_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "The above shows that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DT'),\n",
       "  ('mechanical', 'JJ'),\n",
       "  ('and', 'CC'),\n",
       "  ('material', 'JJ'),\n",
       "  ('properties', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('elderly', 'JJ'),\n",
       "  ('human', 'JJ'),\n",
       "  ('articular', 'JJ'),\n",
       "  ('cartilage', 'NN'),\n",
       "  ('subject', 'JJ'),\n",
       "  ('to', 'TO'),\n",
       "  ('impact', 'VB'),\n",
       "  ('and', 'CC'),\n",
       "  ('slow', 'VB'),\n",
       "  ('loading', 'VBG'),\n",
       "  ('Running', 'VBG'),\n",
       "  ('title', 'NN'),\n",
       "  (':', ':'),\n",
       "  ('Impact', 'NN'),\n",
       "  ('loading', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('composition', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('human', 'JJ'),\n",
       "  ('cartilage', 'NN'),\n",
       "  ('L.V', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('Burgin1', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('L.', 'NNP'),\n",
       "  ('Edelsten2', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('R.M', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('Aspden*', 'NNP'),\n",
       "  ('Musculoskeletal', 'NNP'),\n",
       "  ('Research', 'NNP'),\n",
       "  ('Programme', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('School', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Medicine', 'NNP'),\n",
       "  ('\\\\u0026', 'NNP'),\n",
       "  ('Dentistry', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('University', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Aberdeen', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('Aberdeen', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('UK', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('1Current', 'JJ'),\n",
       "  ('address', 'NN'),\n",
       "  (':', ':'),\n",
       "  ('Medical', 'JJ'),\n",
       "  ('Technologies', 'NNS'),\n",
       "  ('Innovation', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('Knowledge', 'NNP'),\n",
       "  ('Centre', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('X102', 'NNP'),\n",
       "  ('Medical', 'NNP'),\n",
       "  ('and', 'CC'),\n",
       "  ('Biological', 'NNP'),\n",
       "  ('Engineering', 'NNP'),\n",
       "  ('-', ':'),\n",
       "  ('University', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Leeds', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('Leeds', 'NNP'),\n",
       "  (',', ','),\n",
       "  ('LS2', 'NNP'),\n",
       "  ('9JT', 'CD'),\n",
       "  ('.', '.')],\n",
       " [('UK', 'NNP'), ('.', '.')],\n",
       " [('L.V.Burgin', 'NNP'),\n",
       "  ('@', 'NNP'),\n",
       "  ('leeds.ac.uk', 'VBD'),\n",
       "  ('2Current', 'CD'),\n",
       "  ('email', 'NN'),\n",
       "  ('address', 'NN'),\n",
       "  (':', ':'),\n",
       "  ('Lorna.ramsay', 'NNP'),\n",
       "  ('@', 'NNP'),\n",
       "  ('education.gsi.gov.uk', 'VBD'),\n",
       "  ('Corresponding', 'NNP'),\n",
       "  ('Author', 'NNP'),\n",
       "  ('Professor', 'NNP'),\n",
       "  ('R.M', 'NNP'),\n",
       "  ('.', '.')],\n",
       " [('Aspden', 'NNP'),\n",
       "  ('Musculoskeletal', 'NNP'),\n",
       "  ('Research', 'NNP'),\n",
       "  ('Programme', 'NNP'),\n",
       "  ('School', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Medicine', 'NNP'),\n",
       "  ('\\\\u0026', 'NNP'),\n",
       "  ('Dentistry', 'NNP'),\n",
       "  ('University', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Aberdeen', 'NNP'),\n",
       "  ('Institute', 'NNP'),\n",
       "  ('of', 'IN'),\n",
       "  ('Medical', 'NNP'),\n",
       "  ('Sciences', 'NNPS'),\n",
       "  ('Foresterhill', 'NNP'),\n",
       "  ('Aberdeen', 'NNP'),\n",
       "  ('AB25', 'NNP'),\n",
       "  ('2ZD', 'CD'),\n",
       "  ('UK', 'NNP'),\n",
       "  ('Tel', 'NNP'),\n",
       "  (':', ':'),\n",
       "  ('+', 'NN'),\n",
       "  ('(', '('),\n",
       "  ('0', 'CD'),\n",
       "  (')', ')'),\n",
       "  ('1224', 'CD'),\n",
       "  ('437445', 'CD'),\n",
       "  ('e-mail', 'NN'),\n",
       "  (':', ':'),\n",
       "  ('r.aspden', 'JJ'),\n",
       "  ('@', 'NN'),\n",
       "  ('abdn.ac.uk', 'VBD'),\n",
       "  ('1', 'CD'),\n",
       "  ('Abstract', 'NNP'),\n",
       "  ('The', 'DT'),\n",
       "  ('mechanical', 'JJ'),\n",
       "  ('properties', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('articular', 'JJ'),\n",
       "  ('cartilage', 'NN'),\n",
       "  ('vary', 'JJ'),\n",
       "  ('enormously', 'RB'),\n",
       "  ('with', 'IN'),\n",
       "  ('loading', 'VBG'),\n",
       "  ('rate', 'NN'),\n",
       "  (',', ','),\n",
       "  ('and', 'CC'),\n",
       "  ('how', 'WRB'),\n",
       "  ('these', 'DT'),\n",
       "  ('properties', 'NNS'),\n",
       "  ('derive', 'VBP'),\n",
       "  ('from', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('composition', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('structure', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('tissue', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('still', 'RB'),\n",
       "  ('unclear', 'JJ'),\n",
       "  ('.', '.')],\n",
       " [('This', 'DT'),\n",
       "  ('study', 'NN'),\n",
       "  ('investigates', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('mechanical', 'JJ'),\n",
       "  ('properties', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('human', 'JJ'),\n",
       "  ('articular', 'JJ'),\n",
       "  ('cartilage', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('rapid', 'JJ'),\n",
       "  ('rates', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('loading', 'NN'),\n",
       "  (',', ','),\n",
       "  ('compares', 'VBZ'),\n",
       "  ('these', 'DT'),\n",
       "  ('with', 'IN'),\n",
       "  ('measurements', 'NNS'),\n",
       "  ('at', 'IN'),\n",
       "  ('slow', 'JJ'),\n",
       "  ('rates', 'NNS'),\n",
       "  ('of', 'IN'),\n",
       "  ('loading', 'NN'),\n",
       "  ('and', 'CC'),\n",
       "  ('explores', 'VBZ'),\n",
       "  ('how', 'WRB'),\n",
       "  ('they', 'PRP'),\n",
       "  ('relate', 'VBP'),\n",
       "  ('to', 'TO'),\n",
       "  ('the', 'DT'),\n",
       "  ('gross', 'JJ'),\n",
       "  ('composition', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('tissue', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('Full-depth', 'JJ'),\n",
       "  ('femoral', 'JJ'),\n",
       "  ('head', 'NN'),\n",
       "  ('cartilage', 'NN'),\n",
       "  ('biopsies', 'NNS'),\n",
       "  ('were', 'VBD'),\n",
       "  ('subjected', 'VBN'),\n",
       "  ('to', 'TO'),\n",
       "  ('a', 'DT'),\n",
       "  ('slow', 'JJ'),\n",
       "  (',', ','),\n",
       "  ('unconfined', 'JJ'),\n",
       "  ('compression', 'NN'),\n",
       "  ('test', 'NN'),\n",
       "  ('followed', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('an', 'DT'),\n",
       "  ('impact', 'NN'),\n",
       "  ('at', 'IN'),\n",
       "  ('an', 'DT'),\n",
       "  ('energy', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('78.5', 'CD'),\n",
       "  ('mJ', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('velocity', 'NN'),\n",
       "  ('1.25', 'CD'),\n",
       "  ('m', 'JJ'),\n",
       "  ('s-1', 'NN'),\n",
       "  ('.', '.')],\n",
       " [('.', '.')]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_sentences[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunked_sentences = nltk.ne_chunk_sents(tagged_sentences, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object <genexpr> at 0x10e8a02d0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_0 = nltk.ne_chunk_sents(tagged_sentences[0], binary=True)\n",
    "cs_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We showed a simple straight forward NER task on a single article. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_entity_names(t):\n",
    "    entity_names = []\n",
    "\n",
    "    if hasattr(t, 'label') and t.label:\n",
    "        if t.label() == 'NE':\n",
    "            entity_names.append(' '.join([child[0] for child in t]))\n",
    "        else:\n",
    "            for child in t:\n",
    "                entity_names.extend(extract_entity_names(child))\n",
    "\n",
    "    return entity_names\n",
    "\n",
    "entity_names = []\n",
    "for tree in chunked_sentences:\n",
    "    # Print results per sentence\n",
    "    # print extract_entity_names(tree)\n",
    "\n",
    "    entity_names.extend(extract_entity_names(tree))\n",
    "\n",
    "# Print all entity names\n",
    "#print entity_names\n",
    "\n",
    "# Print unique entity names\n",
    "print set(entity_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_sent = \"WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WASHINGTON -- In the wake of a string of abuses by New York police officers in the 1990s, Loretta E. Lynch, the top federal prosecutor in Brooklyn, spoke forcefully about the pain of a broken trust that African-Americans felt and said the responsibility for repairing generations of miscommunication and mistrust fell to law enforcement.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parse_tree = nltk.ne_chunk(nltk.tag.pos_tag(my_sent.split()), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "named_entities = []\n",
    "\n",
    "for t in parse_tree.subtrees():\n",
    "    if t.label() == 'NE':\n",
    "#         named_entities.append(t)\n",
    "        named_entities.append(list(t))  # if you want to save a list of tagged words instead of a tree\n",
    "\n",
    "print(named_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('WASHINGTON', 'NNP')], [('New', 'NNP'), ('York', 'NNP')]]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "named_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_named_entities=[]\n",
    "for tok_sent in tokenized_sentences:\n",
    "    print(tok_sent)\n",
    "    parse_tree = nltk.ne_chunk(nltk.tag.pos_tag(tok_sent), binary=True)\n",
    "    for t in parse_tree.subtrees():\n",
    "        if t.label() == 'NE':\n",
    "            article_named_entities.append(list(t))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
